{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2515a74c",
   "metadata": {},
   "source": [
    "# Data Catalog And Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601aa125",
   "metadata": {},
   "source": [
    "## Data Catalog and Lineage\n",
    "\n",
    "This notebook handles the documentation and tracking of data assets, their origins, and transformations.\n",
    "It establishes a system for maintaining metadata about datasets and tracking how data flows through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import uuid\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e15e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for data catalog management\n",
    "class DataCatalog:\n",
    "    \"\"\"\n",
    "    A class to manage dataset metadata, lineage, and catalog information.\n",
    "    \"\"\"\n",
    "    def __init__(self, catalog_path: str = \"data_catalog.json\"):\n",
    "        \"\"\"\n",
    "        Initialize the data catalog.\n",
    "        \n",
    "        Args:\n",
    "            catalog_path: Path to the catalog JSON file\n",
    "        \"\"\"\n",
    "        self.catalog_path = catalog_path\n",
    "        self.catalog = self._load_catalog()\n",
    "        \n",
    "    def _load_catalog(self) -> Dict:\n",
    "        \"\"\"Load the catalog from file if it exists, otherwise create a new one.\"\"\"\n",
    "        if os.path.exists(self.catalog_path):\n",
    "            with open(self.catalog_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        else:\n",
    "            return {\"datasets\": {}, \"transformations\": {}}\n",
    "    \n",
    "    def save_catalog(self):\n",
    "        \"\"\"Save the catalog to file.\"\"\"\n",
    "        with open(self.catalog_path, 'w') as f:\n",
    "            json.dump(self.catalog, f, indent=2)\n",
    "    \n",
    "    def register_dataset(self, \n",
    "                         dataset_id: str, \n",
    "                         name: str, \n",
    "                         description: str, \n",
    "                         schema: Dict, \n",
    "                         source: str,\n",
    "                         owner: str,\n",
    "                         tags: List[str] = None,\n",
    "                         quality_metrics: Dict = None) -> str:\n",
    "        \"\"\"\n",
    "        Register a dataset in the catalog.\n",
    "        \n",
    "        Args:\n",
    "            dataset_id: Unique identifier for the dataset\n",
    "            name: Name of the dataset\n",
    "            description: Description of the dataset\n",
    "            schema: Schema information\n",
    "            source: Source of the dataset\n",
    "            owner: Owner of the dataset\n",
    "            tags: List of tags for the dataset\n",
    "            quality_metrics: Quality metrics for the dataset\n",
    "            \n",
    "        Returns:\n",
    "            dataset_id: The ID of the registered dataset\n",
    "        \"\"\"\n",
    "        if dataset_id in self.catalog[\"datasets\"]:\n",
    "            print(f\"Dataset {dataset_id} already exists. Updating...\")\n",
    "        \n",
    "        self.catalog[\"datasets\"][dataset_id] = {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"schema\": schema,\n",
    "            \"source\": source,\n",
    "            \"owner\": owner,\n",
    "            \"tags\": tags or [],\n",
    "            \"quality_metrics\": quality_metrics or {},\n",
    "            \"created_at\": datetime.datetime.now().isoformat(),\n",
    "            \"updated_at\": datetime.datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.save_catalog()\n",
    "        return dataset_id\n",
    "    \n",
    "    def register_transformation(self, \n",
    "                               transformation_id: str,\n",
    "                               name: str,\n",
    "                               description: str,\n",
    "                               input_datasets: List[str],\n",
    "                               output_datasets: List[str],\n",
    "                               transformation_code: str = None,\n",
    "                               parameters: Dict = None) -> str:\n",
    "        \"\"\"\n",
    "        Register a data transformation in the catalog.\n",
    "        \n",
    "        Args:\n",
    "            transformation_id: Unique identifier for the transformation\n",
    "            name: Name of the transformation\n",
    "            description: Description of the transformation\n",
    "            input_datasets: List of input dataset IDs\n",
    "            output_datasets: List of output dataset IDs\n",
    "            transformation_code: Code used for the transformation\n",
    "            parameters: Parameters used in the transformation\n",
    "            \n",
    "        Returns:\n",
    "            transformation_id: The ID of the registered transformation\n",
    "        \"\"\"\n",
    "        if transformation_id in self.catalog[\"transformations\"]:\n",
    "            print(f\"Transformation {transformation_id} already exists. Updating...\")\n",
    "        \n",
    "        self.catalog[\"transformations\"][transformation_id] = {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"input_datasets\": input_datasets,\n",
    "            \"output_datasets\": output_datasets,\n",
    "            \"transformation_code\": transformation_code,\n",
    "            \"parameters\": parameters or {},\n",
    "            \"created_at\": datetime.datetime.now().isoformat(),\n",
    "            \"updated_at\": datetime.datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.save_catalog()\n",
    "        return transformation_id\n",
    "    \n",
    "    def get_dataset_lineage(self, dataset_id: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Get the lineage information for a dataset.\n",
    "        \n",
    "        Args:\n",
    "            dataset_id: ID of the dataset\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing upstream and downstream datasets\n",
    "        \"\"\"\n",
    "        if dataset_id not in self.catalog[\"datasets\"]:\n",
    "            raise ValueError(f\"Dataset {dataset_id} not found in catalog\")\n",
    "        \n",
    "        lineage = {\"upstream\": [], \"downstream\": []}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7acc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Find transformations where this dataset is an output (upstream)\n",
    "        for trans_id, trans in self.catalog[\"transformations\"].items():\n",
    "            if dataset_id in trans[\"output_datasets\"]:\n",
    "                lineage[\"upstream\"].append({\n",
    "                    \"transformation_id\": trans_id,\n",
    "                    \"transformation_name\": trans[\"name\"],\n",
    "                    \"input_datasets\": trans[\"input_datasets\"]\n",
    "                })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78612cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Find transformations where this dataset is an input (downstream)\n",
    "        for trans_id, trans in self.catalog[\"transformations\"].items():\n",
    "            if dataset_id in trans[\"input_datasets\"]:\n",
    "                lineage[\"downstream\"].append({\n",
    "                    \"transformation_id\": trans_id,\n",
    "                    \"transformation_name\": trans[\"name\"],\n",
    "                    \"output_datasets\": trans[\"output_datasets\"]\n",
    "                })\n",
    "        \n",
    "        return lineage\n",
    "    \n",
    "    def visualize_lineage(self, dataset_id: str = None):\n",
    "        \"\"\"\n",
    "        Visualize the lineage of datasets.\n",
    "        \n",
    "        Args:\n",
    "            dataset_id: Optional ID of a specific dataset to visualize\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import networkx as nx\n",
    "            \n",
    "            G = nx.DiGraph()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a450941",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Add all datasets as nodes\n",
    "            for ds_id, ds in self.catalog[\"datasets\"].items():\n",
    "                G.add_node(ds_id, label=ds[\"name\"], type=\"dataset\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c144a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Add all transformations as nodes\n",
    "            for trans_id, trans in self.catalog[\"transformations\"].items():\n",
    "                G.add_node(trans_id, label=trans[\"name\"], type=\"transformation\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Add edges from input datasets to transformation\n",
    "                for input_ds in trans[\"input_datasets\"]:\n",
    "                    G.add_edge(input_ds, trans_id)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf762eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Add edges from transformation to output datasets\n",
    "                for output_ds in trans[\"output_datasets\"]:\n",
    "                    G.add_edge(trans_id, output_ds)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # If a specific dataset is provided, filter the graph\n",
    "            if dataset_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead97ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Get all ancestors and descendants\n",
    "                ancestors = nx.ancestors(G, dataset_id)\n",
    "                descendants = nx.descendants(G, dataset_id)\n",
    "                relevant_nodes = ancestors.union(descendants).union({dataset_id})\n",
    "                G = G.subgraph(relevant_nodes)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(G)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Draw dataset nodes\n",
    "            dataset_nodes = [n for n, d in G.nodes(data=True) if d.get(\"type\") == \"dataset\"]\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=dataset_nodes, node_color='skyblue', node_size=500)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Draw transformation nodes\n",
    "            trans_nodes = [n for n, d in G.nodes(data=True) if d.get(\"type\") == \"transformation\"]\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=trans_nodes, node_color='lightgreen', node_size=300, node_shape='s')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Draw edges\n",
    "            nx.draw_networkx_edges(G, pos, arrows=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf78cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Draw labels\n",
    "            labels = {n: G.nodes[n].get(\"label\", n) for n in G.nodes()}\n",
    "            nx.draw_networkx_labels(G, pos, labels=labels, font_size=8)\n",
    "            \n",
    "            plt.title(\"Data Lineage Graph\")\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"Please install networkx to visualize lineage: pip install networkx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for data transformation tracking\n",
    "class DataTransformer:\n",
    "    \"\"\"\n",
    "    A class to track and document data transformations.\n",
    "    \"\"\"\n",
    "    def __init__(self, catalog: DataCatalog):\n",
    "        \"\"\"\n",
    "        Initialize the data transformer.\n",
    "        \n",
    "        Args:\n",
    "            catalog: DataCatalog instance\n",
    "        \"\"\"\n",
    "        self.catalog = catalog\n",
    "        self.transformation_history = []\n",
    "    \n",
    "    def transform(self, \n",
    "                 transformation_func,\n",
    "                 input_data: Dict[str, pd.DataFrame],\n",
    "                 transformation_id: str,\n",
    "                 name: str,\n",
    "                 description: str,\n",
    "                 parameters: Dict = None) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Apply a transformation function and track the lineage.\n",
    "        \n",
    "        Args:\n",
    "            transformation_func: Function that performs the transformation\n",
    "            input_data: Dictionary of input dataframes {dataset_id: dataframe}\n",
    "            transformation_id: Unique identifier for the transformation\n",
    "            name: Name of the transformation\n",
    "            description: Description of the transformation\n",
    "            parameters: Parameters for the transformation\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of output dataframes {dataset_id: dataframe}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Record the start time\n",
    "        start_time = datetime.datetime.now()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b528c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Apply the transformation\n",
    "        output_data = transformation_func(input_data, parameters or {})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11837e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Record the end time\n",
    "        end_time = datetime.datetime.now()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03386de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Record the transformation\n",
    "        transformation_record = {\n",
    "            \"transformation_id\": transformation_id,\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"input_datasets\": list(input_data.keys()),\n",
    "            \"output_datasets\": list(output_data.keys()),\n",
    "            \"parameters\": parameters or {},\n",
    "            \"start_time\": start_time.isoformat(),\n",
    "            \"end_time\": end_time.isoformat(),\n",
    "            \"duration_seconds\": (end_time - start_time).total_seconds()\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Add to history\n",
    "        self.transformation_history.append(transformation_record)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777fea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Register the transformation in the catalog\n",
    "        self.catalog.register_transformation(\n",
    "            transformation_id=transformation_id,\n",
    "            name=name,\n",
    "            description=description,\n",
    "            input_datasets=list(input_data.keys()),\n",
    "            output_datasets=list(output_data.keys()),\n",
    "            parameters=parameters or {}\n",
    "        )\n",
    "        \n",
    "        return output_data\n",
    "    \n",
    "    def get_transformation_history(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get the history of transformations.\n",
    "        \n",
    "        Returns:\n",
    "            List of transformation records\n",
    "        \"\"\"\n",
    "        return self.transformation_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for data profiling and quality metrics\n",
    "class DataProfiler:\n",
    "    \"\"\"\n",
    "    A class to generate data profiles and quality metrics.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def profile_dataframe(df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate a profile of a dataframe.\n",
    "        \n",
    "        Args:\n",
    "            df: Pandas DataFrame to profile\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing profile information\n",
    "        \"\"\"\n",
    "        profile = {\n",
    "            \"shape\": df.shape,\n",
    "            \"columns\": list(df.columns),\n",
    "            \"dtypes\": {col: str(dtype) for col, dtype in df.dtypes.items()},\n",
    "            \"missing_values\": {col: int(df[col].isna().sum()) for col in df.columns},\n",
    "            \"missing_percentage\": {col: float(df[col].isna().mean() * 100) for col in df.columns},\n",
    "            \"unique_values\": {col: int(df[col].nunique()) for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category'},\n",
    "            \"memory_usage\": {col: float(df[col].memory_usage(deep=True) / 1024) for col in df.columns},  # KB\n",
    "            \"total_memory_kb\": float(df.memory_usage(deep=True).sum() / 1024)\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d152cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Add numeric column statistics\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            profile[\"numeric_stats\"] = {}\n",
    "            for col in numeric_cols:\n",
    "                profile[\"numeric_stats\"][col] = {\n",
    "                    \"min\": float(df[col].min()) if not pd.isna(df[col].min()) else None,\n",
    "                    \"max\": float(df[col].max()) if not pd.isna(df[col].max()) else None,\n",
    "                    \"mean\": float(df[col].mean()) if not pd.isna(df[col].mean()) else None,\n",
    "                    \"median\": float(df[col].median()) if not pd.isna(df[col].median()) else None,\n",
    "                    \"std\": float(df[col].std()) if not pd.isna(df[col].std()) else None\n",
    "                }\n",
    "        \n",
    "        return profile\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_quality_metrics(df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate data quality metrics for a dataframe.\n",
    "        \n",
    "        Args:\n",
    "            df: Pandas DataFrame to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing quality metrics\n",
    "        \"\"\"\n",
    "        total_rows = len(df)\n",
    "        total_cells = total_rows * len(df.columns)\n",
    "        missing_cells = df.isna().sum().sum()\n",
    "        \n",
    "        metrics = {\n",
    "            \"completeness\": {\n",
    "                \"score\": float((total_cells - missing_cells) / total_cells * 100),\n",
    "                \"description\": \"Percentage of non-missing values\"\n",
    "            },\n",
    "            \"column_completeness\": {\n",
    "                col: float((total_rows - df[col].isna().sum()) / total_rows * 100) \n",
    "                for col in df.columns\n",
    "            }\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf346000",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Check for duplicated rows\n",
    "        duplicate_rows = df.duplicated().sum()\n",
    "        metrics[\"uniqueness\"] = {\n",
    "            \"score\": float((total_rows - duplicate_rows) / total_rows * 100),\n",
    "            \"description\": \"Percentage of unique rows\"\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f955df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample dataset\n",
    "def load_nz_industry_data():\n",
    "    \"\"\"\n",
    "    This function simulates loading the New Zealand Industry Financial Dataset.\n",
    "    In a real scenario, you would load from a file or database.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame containing the dataset\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a sample of the dataset based on the provided information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # In a real scenario, you would load the actual data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create sample data\n",
    "    years = list(range(2013, 2024))\n",
    "    industry_levels = [\"Level 1\", \"Level 2\", \"Level 3\", \"Level 4\"]\n",
    "    industry_codes = [\"99999\", \"AA111\", \"BB222\", \"CC333\", \"DD444\"]\n",
    "    industry_names = [\"All industries\", \"Agriculture\", \"Manufacturing\", \"Construction\", \"Services\"]\n",
    "    units = [\"Dollars (millions)\"]\n",
    "    variable_codes = [\"H01\", \"H04\", \"H05\", \"H07\", \"H08\"]\n",
    "    variable_names = [\"Total income\", \"Sales, government funding, grants and subsidies\", \n",
    "                     \"Interest, dividends and donations\", \"Non-operating income\", \"Total expenditure\"]\n",
    "    variable_categories = [\"Financial performance\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Generate sample data\n",
    "    data = []\n",
    "    for year in years:\n",
    "        for i, industry_code in enumerate(industry_codes):\n",
    "            for var_code, var_name in zip(variable_codes, variable_names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ad3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Generate a random value\n",
    "                value = np.random.randint(10000, 1000000)\n",
    "                \n",
    "                data.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Industry_aggregation_NZSIOC\": industry_levels[min(i, len(industry_levels)-1)],\n",
    "                    \"Industry_code_NZSIOC\": industry_code,\n",
    "                    \"Industry_name_NZSIOC\": industry_names[i],\n",
    "                    \"Units\": units[0],\n",
    "                    \"Variable_code\": var_code,\n",
    "                    \"Variable_name\": var_name,\n",
    "                    \"Variable_category\": variable_categories[0],\n",
    "                    \"Value\": str(value),\n",
    "                    \"Industry_code_ANZSIC06\": f\"ANZSIC06 divisions A-S (excluding classes K6330, L6711, O7552, O760, O771, O772, S9540, S9601, S9602, and S9603)\"\n",
    "                })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data catalog\n",
    "catalog = DataCatalog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d921ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data transformer\n",
    "transformer = DataTransformer(catalog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ced1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data\n",
    "raw_data = load_nz_industry_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile the raw data\n",
    "profiler = DataProfiler()\n",
    "raw_profile = profiler.profile_dataframe(raw_data)\n",
    "raw_quality = profiler.calculate_quality_metrics(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the raw dataset in the catalog\n",
    "raw_dataset_id = \"nz_industry_financial_raw\"\n",
    "catalog.register_dataset(\n",
    "    dataset_id=raw_dataset_id,\n",
    "    name=\"New Zealand Industry Financial Data (Raw)\",\n",
    "    description=\"Raw financial data for New Zealand industries from 2013 to 2023\",\n",
    "    schema={\n",
    "        \"columns\": raw_profile[\"columns\"],\n",
    "        \"dtypes\": raw_profile[\"dtypes\"]\n",
    "    },\n",
    "    source=\"Annual Enterprise Survey\",\n",
    "    owner=\"Data Science Team\",\n",
    "    tags=[\"financial\", \"industry\", \"new zealand\", \"raw\"],\n",
    "    quality_metrics=raw_quality\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation function to clean the data\n",
    "def clean_data_transformation(input_data, params):\n",
    "    \"\"\"\n",
    "    Clean the raw data by converting types and handling any issues.\n",
    "    \n",
    "    Args:\n",
    "        input_data: Dictionary with input DataFrames\n",
    "        params: Parameters for the transformation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with output DataFrames\n",
    "    \"\"\"\n",
    "    df = input_data[params[\"input_dataset_id\"]].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Convert Value column to numeric\n",
    "    df[\"Value\"] = pd.to_numeric(df[\"Value\"], errors=\"coerce\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1858be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Extract clean industry codes\n",
    "    df[\"Clean_Industry_Code\"] = df[\"Industry_code_NZSIOC\"].str.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5cb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create output\n",
    "    output_data = {params[\"output_dataset_id\"]: df}\n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation\n",
    "clean_params = {\n",
    "    \"input_dataset_id\": raw_dataset_id,\n",
    "    \"output_dataset_id\": \"nz_industry_financial_clean\"\n",
    "}\n",
    "\n",
    "output_data = transformer.transform(\n",
    "    transformation_func=clean_data_transformation,\n",
    "    input_data={raw_dataset_id: raw_data},\n",
    "    transformation_id=\"clean_nz_industry_data\",\n",
    "    name=\"Clean NZ Industry Financial Data\",\n",
    "    description=\"Convert Value column to numeric and extract clean industry codes\",\n",
    "    parameters=clean_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be08c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cleaned data\n",
    "clean_data = output_data[\"nz_industry_financial_clean\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile the cleaned data\n",
    "clean_profile = profiler.profile_dataframe(clean_data)\n",
    "clean_quality = profiler.calculate_quality_metrics(clean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the cleaned dataset\n",
    "clean_dataset_id = \"nz_industry_financial_clean\"\n",
    "catalog.register_dataset(\n",
    "    dataset_id=clean_dataset_id,\n",
    "    name=\"New Zealand Industry Financial Data (Cleaned)\",\n",
    "    description=\"Cleaned financial data for New Zealand industries with proper data types\",\n",
    "    schema={\n",
    "        \"columns\": clean_profile[\"columns\"],\n",
    "        \"dtypes\": clean_profile[\"dtypes\"]\n",
    "    },\n",
    "    source=\"Derived from raw NZ Industry Financial Data\",\n",
    "    owner=\"Data Science Team\",\n",
    "    tags=[\"financial\", \"industry\", \"new zealand\", \"cleaned\"],\n",
    "    quality_metrics=clean_quality\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c4d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation to create aggregated metrics\n",
    "def create_aggregated_metrics(input_data, params):\n",
    "    \"\"\"\n",
    "    Create aggregated financial metrics by year and industry.\n",
    "    \n",
    "    Args:\n",
    "        input_data: Dictionary with input DataFrames\n",
    "        params: Parameters for the transformation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with output DataFrames\n",
    "    \"\"\"\n",
    "    df = input_data[params[\"input_dataset_id\"]].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create pivot table for financial metrics by year and industry\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=[\"Year\", \"Industry_name_NZSIOC\"],\n",
    "        columns=\"Variable_name\",\n",
    "        values=\"Value\",\n",
    "        aggfunc=\"sum\"\n",
    "    ).reset_index()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27268732",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calculate profit (if Total income and Total expenditure are available)\n",
    "    if \"Total income\" in pivot_df.columns and \"Total expenditure\" in pivot_df.columns:\n",
    "        pivot_df[\"Profit\"] = pivot_df[\"Total income\"] - pivot_df[\"Total expenditure\"]\n",
    "        pivot_df[\"Profit_Margin\"] = pivot_df[\"Profit\"] / pivot_df[\"Total income\"] * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create output\n",
    "    output_data = {params[\"output_dataset_id\"]: pivot_df}\n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b25d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation\n",
    "agg_params = {\n",
    "    \"input_dataset_id\": clean_dataset_id,\n",
    "    \"output_dataset_id\": \"nz_industry_financial_aggregated\"\n",
    "}\n",
    "\n",
    "output_data = transformer.transform(\n",
    "    transformation_func=create_aggregated_metrics,\n",
    "    input_data={clean_dataset_id: clean_data},\n",
    "    transformation_id=\"aggregate_nz_industry_data\",\n",
    "    name=\"Aggregate NZ Industry Financial Data\",\n",
    "    description=\"Create aggregated financial metrics by year and industry\",\n",
    "    parameters=agg_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a27a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the aggregated data\n",
    "agg_data = output_data[\"nz_industry_financial_aggregated\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile the aggregated data\n",
    "agg_profile = profiler.profile_dataframe(agg_data)\n",
    "agg_quality = profiler.calculate_quality_metrics(agg_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34045b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the aggregated dataset\n",
    "agg_dataset_id = \"nz_industry_financial_aggregated\"\n",
    "catalog.register_dataset(\n",
    "    dataset_id=agg_dataset_id,\n",
    "    name=\"New Zealand Industry Financial Data (Aggregated)\",\n",
    "    description=\"Aggregated financial metrics by year and industry with calculated profit metrics\",\n",
    "    schema={\n",
    "        \"columns\": agg_profile[\"columns\"],\n",
    "        \"dtypes\": agg_profile[\"dtypes\"]\n",
    "    },\n",
    "    source=\"Derived from cleaned NZ Industry Financial Data\",\n",
    "    owner=\"Data Science Team\",\n",
    "    tags=[\"financial\", \"industry\", \"new zealand\", \"aggregated\", \"metrics\"],\n",
    "    quality_metrics=agg_quality\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation to create time series features\n",
    "def create_time_series_features(input_data, params):\n",
    "    \"\"\"\n",
    "    Create time series features from the aggregated data.\n",
    "    \n",
    "    Args:\n",
    "        input_data: Dictionary with input DataFrames\n",
    "        params: Parameters for the transformation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with output DataFrames\n",
    "    \"\"\"\n",
    "    df = input_data[params[\"input_dataset_id\"]].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd480787",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Ensure data is sorted by Year\n",
    "    df = df.sort_values([\"Industry_name_NZSIOC\", \"Year\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e93f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calculate year-over-year growth for numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31658010",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Group by industry and calculate growth rates\n",
    "    growth_dfs = []\n",
    "    \n",
    "    for industry, group in df.groupby(\"Industry_name_NZSIOC\"):\n",
    "        group = group.sort_values(\"Year\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Calculate growth rates for each numeric column\n",
    "        for col in numeric_cols:\n",
    "            if col != \"Year\":\n",
    "                group[f\"{col}_YoY_Growth\"] = group[col].pct_change() * 100\n",
    "        \n",
    "        growth_dfs.append(group)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Combine all industries back together\n",
    "    ts_df = pd.concat(growth_dfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37121b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create output\n",
    "    output_data = {params[\"output_dataset_id\"]: ts_df}\n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74197d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation\n",
    "ts_params = {\n",
    "    \"input_dataset_id\": agg_dataset_id,\n",
    "    \"output_dataset_id\": \"nz_industry_financial_time_series\"\n",
    "}\n",
    "\n",
    "output_data = transformer.transform(\n",
    "    transformation_func=create_time_series_features,\n",
    "    input_data={agg_dataset_id: agg_data},\n",
    "    transformation_id=\"create_time_series_features\",\n",
    "    name=\"Create Time Series Features\",\n",
    "    description=\"Create year-over-year growth rates and other time series features\",\n",
    "    parameters=ts_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045053c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time series data\n",
    "ts_data = output_data[\"nz_industry_financial_time_series\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile the time series data\n",
    "ts_profile = profiler.profile_dataframe(ts_data)\n",
    "ts_quality = profiler.calculate_quality_metrics(ts_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e195a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the time series dataset\n",
    "ts_dataset_id = \"nz_industry_financial_time_series\"\n",
    "catalog.register_dataset(\n",
    "    dataset_id=ts_dataset_id,\n",
    "    name=\"New Zealand Industry Financial Time Series\",\n",
    "    description=\"Time series features including year-over-year growth rates for financial metrics\",\n",
    "    schema={\n",
    "        \"columns\": ts_profile[\"columns\"],\n",
    "        \"dtypes\": ts_profile[\"dtypes\"]\n",
    "    },\n",
    "    source=\"Derived from aggregated NZ Industry Financial Data\",\n",
    "    owner=\"Data Science Team\",\n",
    "    tags=[\"financial\", \"industry\", \"new zealand\", \"time series\", \"growth rates\"],\n",
    "    quality_metrics=ts_quality\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7480929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data lineage\n",
    "catalog.visualize_lineage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the transformation history\n",
    "print(\"\\nTransformation History:\")\n",
    "for i, trans in enumerate(transformer.get_transformation_history()):\n",
    "    print(f\"\\n{i+1}. {trans['name']}\")\n",
    "    print(f\"   ID: {trans['transformation_id']}\")\n",
    "    print(f\"   Description: {trans['description']}\")\n",
    "    print(f\"   Input datasets: {trans['input_datasets']}\")\n",
    "    print(f\"   Output datasets: {trans['output_datasets']}\")\n",
    "    print(f\"   Duration: {trans['duration_seconds']:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67839bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lineage for the final dataset\n",
    "print(\"\\nLineage for Time Series Dataset:\")\n",
    "lineage = catalog.get_dataset_lineage(ts_dataset_id)\n",
    "print(json.dumps(lineage, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final catalog\n",
    "catalog.save_catalog()\n",
    "print(\"\\nData catalog saved to:\", catalog.catalog_path)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}