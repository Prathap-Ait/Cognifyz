{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2cd105",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97faf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4109ce7",
   "metadata": {},
   "source": [
    "## Data Cleansing\n",
    "\n",
    "This notebook focuses on improving data quality by handling missing values, outliers, and other data issues.\n",
    "The goal is to prepare a clean dataset for further analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11651a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Replace 'your_data_file.csv' with the actual file path\n",
    "df = pd.read_csv('your_data_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b40898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6103500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset appears to have no missing values based on the provided info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96aebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we'll include code for handling missing values as a best practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e370fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numeric columns, we could fill with mean/median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical columns, we could fill with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37fc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd284b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Value'] = df['Value'].fillna(df['Value'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Industry_name_NZSIOC'] = df['Industry_name_NZSIOC'].fillna(df['Industry_name_NZSIOC'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fix data type issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e27f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Value' column from object to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8af753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check if there are any non-numeric values\n",
    "print(\"\\nSample values from 'Value' column:\")\n",
    "print(df['Value'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Value' column to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456fab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using errors='coerce' to convert any non-numeric values to NaN\n",
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any NaN values were introduced during conversion\n",
    "print(\"\\nNaN values in 'Value' after conversion:\", df['Value'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are NaN values, we can investigate and handle them\n",
    "if df['Value'].isna().sum() > 0:\n",
    "    print(\"Examples of rows with non-numeric 'Value':\")\n",
    "    print(df[df['Value'].isna()].head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Fill NaN values with median or drop rows based on analysis\n",
    "    df['Value'] = df['Value'].fillna(df['Value'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Detecting and handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66962d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Z-scores for the 'Value' column\n",
    "z_scores = stats.zscore(df['Value'])\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "outliers = (abs_z_scores > 3)  # Threshold of 3 standard deviations\n",
    "\n",
    "print(\"\\nNumber of outliers in 'Value' column:\", np.sum(outliers))\n",
    "print(\"Percentage of outliers:\", (np.sum(outliers) / len(df)) * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of 'Value' to understand outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Value'], kde=True)\n",
    "plt.title('Distribution of Value')\n",
    "plt.xlabel('Value (in millions)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers with a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=df['Value'])\n",
    "plt.title('Box Plot of Value')\n",
    "plt.ylabel('Value (in millions)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers - we can cap them at a certain percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a common approach for financial data where extreme values might be valid\n",
    "Q1 = df['Value'].quantile(0.25)\n",
    "Q3 = df['Value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(\"\\nOutlier thresholds for 'Value':\")\n",
    "print(f\"Lower bound: {lower_bound}\")\n",
    "print(f\"Upper bound: {upper_bound}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595bfe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original data before capping outliers\n",
    "df_original = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc72587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap the outliers\n",
    "df['Value_capped'] = df['Value'].clip(lower=lower_bound, upper=upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs capped values\n",
    "print(\"\\nOriginal 'Value' statistics:\")\n",
    "print(df['Value'].describe())\n",
    "print(\"\\nCapped 'Value' statistics:\")\n",
    "print(df['Value_capped'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12389ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ec026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If duplicates exist, remove them\n",
    "if duplicate_count > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Removed {duplicate_count} duplicate rows. New shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a66265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Standardizing formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Industry_code_ANZSIC06 - extract just the code part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54491833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's examine the format\n",
    "print(\"\\nSample ANZSIC06 codes:\")\n",
    "print(df['Industry_code_ANZSIC06'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the main ANZSIC06 code (assuming it's the part before any spaces or special characters)\n",
    "df['ANZSIC06_clean'] = df['Industry_code_ANZSIC06'].str.extract(r'(ANZSIC06 [A-Za-z0-9\\-]+)')\n",
    "\n",
    "print(\"\\nCleaned ANZSIC06 codes:\")\n",
    "print(df['ANZSIC06_clean'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f47f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Year format (ensure it's treated as a year, not just a number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime year\n",
    "df['Year'] = pd.to_datetime(df['Year'], format='%Y').dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for the decade\n",
    "df['Decade'] = (df['Year'] // 10) * 10\n",
    "print(\"\\nDecade distribution:\")\n",
    "print(df['Decade'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c0a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Additional data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db60e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for consistency between industry codes and names\n",
    "industry_code_name_pairs = df[['Industry_code_NZSIOC', 'Industry_name_NZSIOC']].drop_duplicates()\n",
    "print(f\"\\nUnique industry code-name pairs: {len(industry_code_name_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any industry code has multiple names\n",
    "code_name_counts = df.groupby('Industry_code_NZSIOC')['Industry_name_NZSIOC'].nunique()\n",
    "inconsistent_codes = code_name_counts[code_name_counts > 1]\n",
    "\n",
    "if len(inconsistent_codes) > 0:\n",
    "    print(\"\\nInconsistent industry codes (multiple names):\")\n",
    "    print(inconsistent_codes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa791778",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Show examples of inconsistencies\n",
    "    for code in inconsistent_codes.index[:3]:  # Show first 3 examples\n",
    "        print(f\"\\nCode {code} has these different names:\")\n",
    "        print(df[df['Industry_code_NZSIOC'] == code]['Industry_name_NZSIOC'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Final cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d76c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and reorder columns for the final dataset\n",
    "final_columns = [\n",
    "    'Year', 'Decade', 'Industry_aggregation_NZSIOC', \n",
    "    'Industry_code_NZSIOC', 'Industry_name_NZSIOC',\n",
    "    'ANZSIC06_clean', 'Variable_code', 'Variable_name',\n",
    "    'Variable_category', 'Value', 'Value_capped', 'Units'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fdf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final cleaned dataframe\n",
    "df_cleaned = df[final_columns]\n",
    "\n",
    "print(\"\\nFinal cleaned dataset:\")\n",
    "print(df_cleaned.head())\n",
    "print(\"\\nCleaned dataset info:\")\n",
    "df_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv('nz_industry_financial_data_cleaned.csv', index=False)\n",
    "print(\"\\nCleaned dataset saved to 'nz_industry_financial_data_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save the original dataset with outliers identified\n",
    "df_original['is_outlier'] = outliers\n",
    "df_original.to_csv('nz_industry_financial_data_with_outliers_flagged.csv', index=False)\n",
    "print(\"Original dataset with outliers flagged saved to 'nz_industry_financial_data_with_outliers_flagged.csv'\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}