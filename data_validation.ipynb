{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59bc736",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce74a4",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "\n",
    "This notebook ensures data quality through various validation checks.\n",
    "It verifies that the data meets expected schema, statistical properties, and business rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c3c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this notebook, we'll assume the data is in a CSV file named 'nz_industry_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a real scenario, you would replace this with the actual file path\n",
    "print(\"Loading dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv('nz_industry_data.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset file not found. Creating sample data based on the provided information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c88afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a sample dataset based on the information provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # This is just for demonstration purposes\n",
    "    years = range(2013, 2024)\n",
    "    industry_levels = ['Level 1', 'Level 2', 'Level 3', 'Level 4']\n",
    "    industry_codes = ['99999', 'AA111', 'BB222', 'CC333', 'DD444']\n",
    "    industry_names = ['All industries', 'Agriculture', 'Manufacturing', 'Services', 'Retail']\n",
    "    units = ['Dollars (millions)']\n",
    "    variable_codes = ['H01', 'H04', 'H05', 'H07', 'H08']\n",
    "    variable_names = ['Total income', 'Sales, government funding, grants and subsidies', \n",
    "                      'Interest, dividends and donations', 'Non-operating income', 'Total expenditure']\n",
    "    variable_categories = ['Financial performance']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24484b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create sample data\n",
    "    data = []\n",
    "    for year in years:\n",
    "        for i in range(len(industry_codes)):\n",
    "            for j in range(len(variable_codes)):\n",
    "                value = np.random.randint(10000, 1000000)\n",
    "                anzsic_code = f\"ANZSIC06 divisions A-S (excluding classes K6330, L6711)\"\n",
    "                data.append([year, industry_levels[min(i, len(industry_levels)-1)], \n",
    "                           industry_codes[i], industry_names[i], units[0], \n",
    "                           variable_codes[j], variable_names[j], variable_categories[0], \n",
    "                           str(value), anzsic_code])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Year', 'Industry_aggregation_NZSIOC', 'Industry_code_NZSIOC',\n",
    "                                    'Industry_name_NZSIOC', 'Units', 'Variable_code', 'Variable_name',\n",
    "                                    'Variable_category', 'Value', 'Industry_code_ANZSIC06'])\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Schema Validation\n",
    "print(\"=\"*80)\n",
    "print(\"1. SCHEMA VALIDATION\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Check dataframe shape\n",
    "print(f\"DataFrame Shape: {df.shape}\")\n",
    "expected_shape = (50985, 10)\n",
    "if df.shape == expected_shape:\n",
    "    print(f\"✓ Shape validation passed: {df.shape} matches expected {expected_shape}\")\n",
    "else:\n",
    "    print(f\"✗ Shape validation failed: {df.shape} does not match expected {expected_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b530c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Check column names\n",
    "expected_columns = ['Year', 'Industry_aggregation_NZSIOC', 'Industry_code_NZSIOC',\n",
    "                   'Industry_name_NZSIOC', 'Units', 'Variable_code', 'Variable_name',\n",
    "                   'Variable_category', 'Value', 'Industry_code_ANZSIC06']\n",
    "\n",
    "missing_columns = set(expected_columns) - set(df.columns)\n",
    "extra_columns = set(df.columns) - set(expected_columns)\n",
    "\n",
    "if len(missing_columns) == 0 and len(extra_columns) == 0:\n",
    "    print(\"✓ Column names validation passed: All expected columns are present\")\n",
    "else:\n",
    "    if len(missing_columns) > 0:\n",
    "        print(f\"✗ Missing columns: {missing_columns}\")\n",
    "    if len(extra_columns) > 0:\n",
    "        print(f\"✗ Extra columns: {extra_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5692a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Check data types\n",
    "print(\"\\nColumn Data Types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136bc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Year is integer\n",
    "if df['Year'].dtype == 'int64':\n",
    "    print(\"✓ 'Year' column is correctly typed as int64\")\n",
    "else:\n",
    "    print(f\"✗ 'Year' column is {df['Year'].dtype}, expected int64\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Check for null values\n",
    "null_counts = df.isnull().sum()\n",
    "print(\"\\nNull Value Counts:\")\n",
    "print(null_counts)\n",
    "\n",
    "if null_counts.sum() == 0:\n",
    "    print(\"✓ No null values found in the dataset\")\n",
    "else:\n",
    "    print(f\"✗ Found {null_counts.sum()} null values in the dataset\")\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Statistical Validation\n",
    "print(\"=\"*80)\n",
    "print(\"2. STATISTICAL VALIDATION\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74859cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Check Year range\n",
    "year_min = df['Year'].min()\n",
    "year_max = df['Year'].max()\n",
    "expected_year_min = 2013\n",
    "expected_year_max = 2023\n",
    "\n",
    "print(f\"Year range: {year_min} to {year_max}\")\n",
    "if year_min == expected_year_min and year_max == expected_year_max:\n",
    "    print(f\"✓ Year range validation passed: {year_min} to {year_max}\")\n",
    "else:\n",
    "    print(f\"✗ Year range validation failed: Expected {expected_year_min} to {expected_year_max}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Convert Value column to numeric\n",
    "print(\"\\nConverting 'Value' column to numeric...\")\n",
    "df['Value_numeric'] = pd.to_numeric(df['Value'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for conversion failures\n",
    "if df['Value_numeric'].isna().sum() > 0:\n",
    "    print(f\"✗ {df['Value_numeric'].isna().sum()} values could not be converted to numeric\")\n",
    "else:\n",
    "    print(\"✓ All values successfully converted to numeric\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Check Value distribution\n",
    "print(\"\\nValue Distribution Statistics:\")\n",
    "value_stats = df['Value_numeric'].describe()\n",
    "print(value_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d98a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative values (which might be invalid for financial data)\n",
    "neg_values = (df['Value_numeric'] < 0).sum()\n",
    "if neg_values > 0:\n",
    "    print(f\"✗ Found {neg_values} negative values in 'Value' column\")\n",
    "else:\n",
    "    print(\"✓ No negative values found in 'Value' column\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Check for outliers using IQR method\n",
    "Q1 = df['Value_numeric'].quantile(0.25)\n",
    "Q3 = df['Value_numeric'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = ((df['Value_numeric'] < lower_bound) | (df['Value_numeric'] > upper_bound)).sum()\n",
    "outlier_percentage = (outliers / len(df)) * 100\n",
    "\n",
    "print(f\"\\nOutlier Analysis (IQR method):\")\n",
    "print(f\"Lower bound: {lower_bound}\")\n",
    "print(f\"Upper bound: {upper_bound}\")\n",
    "print(f\"Number of outliers: {outliers} ({outlier_percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d692713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Value distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Value_numeric'], kde=True)\n",
    "plt.title('Distribution of Value')\n",
    "plt.xlabel('Value (in millions)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(lower_bound, color='r', linestyle='--', label=f'Lower bound: {lower_bound:.2f}')\n",
    "plt.axvline(upper_bound, color='r', linestyle='--', label=f'Upper bound: {upper_bound:.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Check distribution of categorical variables\n",
    "print(\"\\nDistribution of Industry Aggregation Levels:\")\n",
    "industry_level_counts = df['Industry_aggregation_NZSIOC'].value_counts()\n",
    "print(industry_level_counts)\n",
    "\n",
    "print(\"\\nDistribution of Variable Categories:\")\n",
    "variable_category_counts = df['Variable_category'].value_counts()\n",
    "print(variable_category_counts)\n",
    "\n",
    "print(\"\\nDistribution of Units:\")\n",
    "units_counts = df['Units'].value_counts()\n",
    "print(units_counts)\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bebb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Business Rule Validation\n",
    "print(\"=\"*80)\n",
    "print(\"3. BUSINESS RULE VALIDATION\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Check if all years have similar number of records (balanced dataset)\n",
    "year_counts = df['Year'].value_counts().sort_index()\n",
    "print(\"Records per year:\")\n",
    "print(year_counts)\n",
    "\n",
    "year_count_std = year_counts.std()\n",
    "year_count_mean = year_counts.mean()\n",
    "year_count_cv = year_count_std / year_count_mean  # Coefficient of variation\n",
    "\n",
    "if year_count_cv < 0.1:  # Less than 10% variation\n",
    "    print(f\"✓ Year distribution is balanced (CV: {year_count_cv:.4f})\")\n",
    "else:\n",
    "    print(f\"✗ Year distribution is imbalanced (CV: {year_count_cv:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Check if \"All industries\" totals are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33937267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each year, the \"All industries\" total income should be greater than or equal to any individual industry\n",
    "print(\"\\nChecking 'All industries' total income consistency...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f245ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Total income variable\n",
    "total_income = df[df['Variable_name'] == 'Total income'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e43709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Year and check if \"All industries\" has the highest value\n",
    "all_industries_check = []\n",
    "for year, group in total_income.groupby('Year'):\n",
    "    all_ind = group[group['Industry_name_NZSIOC'] == 'All industries']['Value_numeric'].values\n",
    "    if len(all_ind) == 0:\n",
    "        continue\n",
    "    all_ind_value = all_ind[0]\n",
    "    max_ind_value = group['Value_numeric'].max()\n",
    "    \n",
    "    if all_ind_value >= max_ind_value:\n",
    "        all_industries_check.append(True)\n",
    "    else:\n",
    "        all_industries_check.append(False)\n",
    "        print(f\"✗ In year {year}, 'All industries' value ({all_ind_value}) is not the maximum value ({max_ind_value})\")\n",
    "\n",
    "if all(all_industries_check) and len(all_industries_check) > 0:\n",
    "    print(\"✓ 'All industries' total income is consistent across all years\")\n",
    "elif len(all_industries_check) == 0:\n",
    "    print(\"! Could not verify 'All industries' consistency - data may be missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Check if Total income >= Total expenditure for each industry and year\n",
    "print(\"\\nChecking income >= expenditure business rule...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get income and expenditure data\n",
    "income_exp_check = []\n",
    "for (year, industry), group in df[df['Variable_name'].isin(['Total income', 'Total expenditure'])].groupby(['Year', 'Industry_name_NZSIOC']):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "        \n",
    "    income = group[group['Variable_name'] == 'Total income']['Value_numeric'].values\n",
    "    expenditure = group[group['Variable_name'] == 'Total expenditure']['Value_numeric'].values\n",
    "    \n",
    "    if len(income) == 0 or len(expenditure) == 0:\n",
    "        continue\n",
    "        \n",
    "    income_value = income[0]\n",
    "    expenditure_value = expenditure[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Allow for small differences due to rounding or other factors\n",
    "    if income_value >= expenditure_value * 0.5:  # Income should be at least 50% of expenditure as a loose rule\n",
    "        income_exp_check.append(True)\n",
    "    else:\n",
    "        income_exp_check.append(False)\n",
    "        print(f\"✗ In year {year}, industry '{industry}' has income ({income_value}) < 50% of expenditure ({expenditure_value})\")\n",
    "\n",
    "if all(income_exp_check) and len(income_exp_check) > 0:\n",
    "    print(\"✓ Income and expenditure relationships are reasonable\")\n",
    "elif len(income_exp_check) == 0:\n",
    "    print(\"! Could not verify income/expenditure relationship - data may be missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Check if industry codes match industry names consistently\n",
    "print(\"\\nChecking industry code-name consistency...\")\n",
    "\n",
    "industry_code_name_map = df[['Industry_code_NZSIOC', 'Industry_name_NZSIOC']].drop_duplicates()\n",
    "industry_code_counts = industry_code_name_map['Industry_code_NZSIOC'].value_counts()\n",
    "industry_name_counts = industry_code_name_map['Industry_name_NZSIOC'].value_counts()\n",
    "\n",
    "inconsistent_codes = industry_code_counts[industry_code_counts > 1]\n",
    "inconsistent_names = industry_name_counts[industry_name_counts > 1]\n",
    "\n",
    "if len(inconsistent_codes) == 0:\n",
    "    print(\"✓ Each industry code maps to exactly one industry name\")\n",
    "else:\n",
    "    print(f\"✗ Found {len(inconsistent_codes)} industry codes that map to multiple industry names\")\n",
    "    for code in inconsistent_codes.index:\n",
    "        names = industry_code_name_map[industry_code_name_map['Industry_code_NZSIOC'] == code]['Industry_name_NZSIOC'].unique()\n",
    "        print(f\"  Code {code} maps to: {names}\")\n",
    "\n",
    "if len(inconsistent_names) == 0:\n",
    "    print(\"✓ Each industry name maps to exactly one industry code\")\n",
    "else:\n",
    "    print(f\"✗ Found {len(inconsistent_names)} industry names that map to multiple industry codes\")\n",
    "    for name in inconsistent_names.index:\n",
    "        codes = industry_code_name_map[industry_code_name_map['Industry_name_NZSIOC'] == name]['Industry_code_NZSIOC'].unique()\n",
    "        print(f\"  Name '{name}' maps to codes: {codes}\")\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Quality Checks\n",
    "print(\"=\"*80)\n",
    "print(\"4. DATA QUALITY CHECKS\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9323eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Check for duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "if duplicate_count == 0:\n",
    "    print(\"✓ No duplicate rows found\")\n",
    "else:\n",
    "    print(f\"✗ Found {duplicate_count} duplicate rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c75917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Check for consistency in units\n",
    "unique_units = df['Units'].unique()\n",
    "print(f\"\\nUnique units in the dataset: {unique_units}\")\n",
    "if len(unique_units) == 1 and 'Dollars (millions)' in unique_units:\n",
    "    print(\"✓ Units are consistent: 'Dollars (millions)'\")\n",
    "else:\n",
    "    print(f\"✗ Units are inconsistent: found {len(unique_units)} different units\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ad476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Check for consistency in variable categories\n",
    "unique_categories = df['Variable_category'].unique()\n",
    "print(f\"\\nUnique variable categories: {unique_categories}\")\n",
    "if len(unique_categories) <= 3:  # Allowing for a reasonable number of categories\n",
    "    print(f\"✓ Variable categories are consistent: {unique_categories}\")\n",
    "else:\n",
    "    print(f\"✗ Too many variable categories: {len(unique_categories)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70aad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Check for unusual patterns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for industries with extreme changes year over year\n",
    "print(\"\\nChecking for unusual year-over-year changes...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on Total income for this check\n",
    "total_income = df[df['Variable_name'] == 'Total income'].copy()\n",
    "if len(total_income) > 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calculate year-over-year change for each industry\n",
    "    yoy_changes = []\n",
    "    for industry, group in total_income.groupby('Industry_name_NZSIOC'):\n",
    "        group = group.sort_values('Year')\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "            \n",
    "        group['prev_value'] = group['Value_numeric'].shift(1)\n",
    "        group['yoy_change'] = (group['Value_numeric'] - group['prev_value']) / group['prev_value']\n",
    "        group = group.dropna()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609262eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Find extreme changes (more than 100% increase or 50% decrease)\n",
    "        extreme_changes = group[(group['yoy_change'] > 1.0) | (group['yoy_change'] < -0.5)]\n",
    "        \n",
    "        for _, row in extreme_changes.iterrows():\n",
    "            yoy_changes.append({\n",
    "                'Industry': industry,\n",
    "                'Year': row['Year'],\n",
    "                'Previous Value': row['prev_value'],\n",
    "                'Current Value': row['Value_numeric'],\n",
    "                'Change %': row['yoy_change'] * 100\n",
    "            })\n",
    "    \n",
    "    if len(yoy_changes) > 0:\n",
    "        print(f\"✗ Found {len(yoy_changes)} instances of extreme year-over-year changes:\")\n",
    "        yoy_df = pd.DataFrame(yoy_changes)\n",
    "        print(yoy_df.head(10))  # Show first 10 extreme changes\n",
    "    else:\n",
    "        print(\"✓ No extreme year-over-year changes detected\")\n",
    "else:\n",
    "    print(\"! Could not check year-over-year changes - 'Total income' data may be missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25553c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 Check for consistency in ANZSIC06 codes\n",
    "print(\"\\nChecking ANZSIC06 code consistency...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the main part of the ANZSIC06 code (before any exclusions)\n",
    "df['ANZSIC06_main'] = df['Industry_code_ANZSIC06'].str.extract(r'(ANZSIC06 [^(]+)')\n",
    "\n",
    "anzsic_counts = df['ANZSIC06_main'].value_counts()\n",
    "if len(anzsic_counts) <= 10:  # Allowing for a reasonable number of main ANZSIC patterns\n",
    "    print(f\"✓ ANZSIC06 codes follow consistent patterns ({len(anzsic_counts)} main patterns)\")\n",
    "else:\n",
    "    print(f\"✗ ANZSIC06 codes have too many patterns ({len(anzsic_counts)} main patterns)\")\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Reporting Validation Results\n",
    "print(\"=\"*80)\n",
    "print(\"5. VALIDATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ed5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of validation results\n",
    "validation_results = {\n",
    "    'Schema Validation': {\n",
    "        'Shape Check': df.shape == expected_shape,\n",
    "        'Column Names': len(missing_columns) == 0 and len(extra_columns) == 0,\n",
    "        'Data Types': df['Year'].dtype == 'int64',\n",
    "        'Null Values': null_counts.sum() == 0\n",
    "    },\n",
    "    'Statistical Validation': {\n",
    "        'Year Range': year_min == expected_year_min and year_max == expected_year_max,\n",
    "        'Value Conversion': df['Value_numeric'].isna().sum() == 0,\n",
    "        'Negative Values': neg_values == 0,\n",
    "        'Outliers': outlier_percentage < 5.0  # Less than 5% outliers is acceptable\n",
    "    },\n",
    "    'Business Rule Validation': {\n",
    "        'Balanced Years': year_count_cv < 0.1,\n",
    "        'All Industries Consistency': all(all_industries_check) if len(all_industries_check) > 0 else None,\n",
    "        'Income-Expenditure Relation': all(income_exp_check) if len(income_exp_check) > 0 else None,\n",
    "        'Code-Name Consistency': len(inconsistent_codes) == 0 and len(inconsistent_names) == 0\n",
    "    },\n",
    "    'Data Quality': {\n",
    "        'No Duplicates': duplicate_count == 0,\n",
    "        'Consistent Units': len(unique_units) == 1 and 'Dollars (millions)' in unique_units,\n",
    "        'Consistent Categories': len(unique_categories) <= 3,\n",
    "        'No Extreme Changes': len(yoy_changes) == 0 if 'yoy_changes' in locals() else None,\n",
    "        'ANZSIC06 Consistency': len(anzsic_counts) <= 10\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d953700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for better visualization\n",
    "results_list = []\n",
    "for category, checks in validation_results.items():\n",
    "    for check_name, result in checks.items():\n",
    "        status = \"PASS\" if result == True else \"FAIL\" if result == False else \"UNKNOWN\"\n",
    "        results_list.append({\n",
    "            'Category': category,\n",
    "            'Check': check_name,\n",
    "            'Status': status\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69296387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"Validation Results Summary:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pass rate\n",
    "pass_count = (results_df['Status'] == 'PASS').sum()\n",
    "total_checks = len(results_df[results_df['Status'] != 'UNKNOWN'])\n",
    "pass_rate = (pass_count / total_checks) * 100 if total_checks > 0 else 0\n",
    "\n",
    "print(f\"\\nOverall Pass Rate: {pass_rate:.2f}% ({pass_count}/{total_checks} checks passed)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations based on failed checks\n",
    "failed_checks = results_df[results_df['Status'] == 'FAIL']\n",
    "if len(failed_checks) > 0:\n",
    "    print(\"\\nRecommendations for Failed Checks:\")\n",
    "    for _, row in failed_checks.iterrows():\n",
    "        category = row['Category']\n",
    "        check = row['Check']\n",
    "        \n",
    "        if category == 'Schema Validation':\n",
    "            if check == 'Shape Check':\n",
    "                print(\"- Verify the dataset is complete and has the expected number of records\")\n",
    "            elif check == 'Column Names':\n",
    "                print(\"- Check for missing or extra columns and align with expected schema\")\n",
    "            elif check == 'Data Types':\n",
    "                print(\"- Convert Year column to integer type\")\n",
    "            elif check == 'Null Values':\n",
    "                print(\"- Handle or investigate null values in the dataset\")\n",
    "                \n",
    "        elif category == 'Statistical Validation':\n",
    "            if check == 'Year Range':\n",
    "                print(\"- Verify the dataset covers the expected time period\")\n",
    "            elif check == 'Value Conversion':\n",
    "                print(\"- Clean the Value column to ensure all entries can be converted to numeric\")\n",
    "            elif check == 'Negative Values':\n",
    "                print(\"- Investigate negative values in financial data\")\n",
    "            elif check == 'Outliers':\n",
    "                print(\"- Review outliers in the Value column\")\n",
    "                \n",
    "        elif category == 'Business Rule Validation':\n",
    "            if check == 'Balanced Years':\n",
    "                print(\"- Investigate why some years have significantly different record counts\")\n",
    "            elif check == 'All Industries Consistency':\n",
    "                print(\"- Check why 'All industries' totals are inconsistent with individual industries\")\n",
    "            elif check == 'Income-Expenditure Relation':\n",
    "                print(\"- Review cases where income is significantly less than expenditure\")\n",
    "            elif check == 'Code-Name Consistency':\n",
    "                print(\"- Standardize industry code to name mappings\")\n",
    "                \n",
    "        elif category == 'Data Quality':\n",
    "            if check == 'No Duplicates':\n",
    "                print(\"- Remove duplicate records from the dataset\")\n",
    "            elif check == 'Consistent Units':\n",
    "                print(\"- Standardize units across the dataset\")\n",
    "            elif check == 'Consistent Categories':\n",
    "                print(\"- Review and consolidate variable categories\")\n",
    "            elif check == 'No Extreme Changes':\n",
    "                print(\"- Investigate industries with extreme year-over-year changes\")\n",
    "            elif check == 'ANZSIC06 Consistency':\n",
    "                print(\"- Standardize ANZSIC06 code formats\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation results to CSV\n",
    "results_df.to_csv('validation_results.csv', index=False)\n",
    "print(\"\\nValidation results saved to 'validation_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0852be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of validation results\n",
    "plt.figure(figsize=(10, 6))\n",
    "status_counts = results_df['Status'].value_counts()\n",
    "colors = {'PASS': 'green', 'FAIL': 'red', 'UNKNOWN': 'gray'}\n",
    "status_counts.plot(kind='bar', color=[colors[x] for x in status_counts.index])\n",
    "plt.title('Validation Results Summary')\n",
    "plt.xlabel('Status')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of validation results by category\n",
    "plt.figure(figsize=(12, 8))\n",
    "category_results = results_df.pivot_table(\n",
    "    index='Category', \n",
    "    columns='Status', \n",
    "    aggfunc='size', \n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "category_results.plot(kind='bar', stacked=True, color=[colors[x] for x in category_results.columns])\n",
    "plt.title('Validation Results by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Status')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData validation complete.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}